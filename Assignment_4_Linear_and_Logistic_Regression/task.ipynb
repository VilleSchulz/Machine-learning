{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf75b96",
   "metadata": {},
   "source": [
    "# Assignment: Linear and logistic regression\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The objectives of this assignment are:\n",
    "1. to learn to use linear regression for predicting continuously varying target variables \n",
    "2. to learn to use logistic regression for binary classification\n",
    "3. to learn to estimate the relative importance of input features\n",
    "\n",
    "## Setup\n",
    "\n",
    "In this assignment, use the Real Estate Valuation dataset that is available at [https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set](https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set). The data is collected from New Taipei City, Taiwan. \n",
    "\n",
    "## Task\n",
    "\n",
    "The assignment consists of constructing *two* separate models for predicting the real estate prices in the dataset: one with linear and one with logistic regression.\n",
    "\n",
    "1. **Linear regression model**: construct a linear regression model for predicting the continuous target variable \"Y house price of unit area\" in the dataset.\n",
    "\n",
    "2. **Logistic regression model**: convert the target variable into a binary-valued one according to whether the original target value is above or below the average house price of unit area (within the training set samples), and construct a binary classifier for predicting its value with logistic regression.\n",
    "\n",
    "Both models should be validated, with appropriate metrics presented and discussed. \n",
    "\n",
    "Remember to draw conclusions from your results and interpret your findings! Can you e.g. estimate which of the input variables has the most important role when predicting the house prices, and which ones are less important? Also, give some thought to whether the input data should be standardized before modeling or not. \n",
    "\n",
    "Prepare a Jupyter notebook containing a full account of the problem treatment. Construct your notebook to include sections for each of the six separate stages in the CRISP-DM model, with appropriate contents (include subsections for the two separate tasks in \"Modeling\" and \"Evaluation\").\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Submit a GitHub permalink that points to the Jupyter notebook as instructed in Oma. The submitted notebook must contain the problem analysis written in accordance with the CRISP-DM process model, complete with Markdown blocks and comments that clearly explain what has been done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ec135",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "The aim of this assignment is to predict real estate prices using the Real Estate Valuation dataset from New Taipei City, Taiwan. Two models are included: first, a linear regression model to predict the continuous target variable “house price of unit area,” and second, a logistic regression model to classify whether the price is above or below the average value in the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99672bf9",
   "metadata": {},
   "source": [
    "## Data understanding\n",
    "Dataset is imported from UC Irvine Machine Learning Repository, by using their python package. It consists of real estate valuation data taken from Sindian Dist., New Taipei City, Taiwan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db80ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "real_estate_valuation = fetch_ucirepo(id=477) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = real_estate_valuation.data.features \n",
    "y = real_estate_valuation.data.targets\n",
    "\n",
    "# Combining features and target variable into a single dataframe\n",
    "df = X.copy()\n",
    "df['Y house price of unit area'] = y\n",
    "display(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59801b1f",
   "metadata": {},
   "source": [
    "There are 6 features and one target variable in dataset and 414 instances.\n",
    "Feature types are integer and float.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# variable information \n",
    "display(real_estate_valuation.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "number_of_plots = len(X.columns)\n",
    "\n",
    "rows, cols = (number_of_plots + 2) // 3, 3  \n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(X.columns):\n",
    "    axes[i].scatter(X[col], y, s=10)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Y House Price of Unit Area')\n",
    "    axes[i].set_title(f\"Plot {i+1}\")\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdb3f3",
   "metadata": {},
   "source": [
    "From these plots we can see that features doesnt have linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e19cd7120f471",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "lat = df[\"X5 latitude\"]\n",
    "lon = df[\"X6 longitude\"]\n",
    "value = df[\"Y house price of unit area\"]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create 3D figure\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Scatter plot in 3D\n",
    "sc = ax.scatter(lat, lon, value, c=value, cmap=\"viridis\", s=50)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"Latitude\")\n",
    "ax.set_ylabel(\"Longitude\")\n",
    "ax.set_zlabel(\"Value\")\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(sc, ax=ax, shrink=0.6, label=\"Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fafdd",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we change the datatypes for all columns to float"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df5d3bd239344652"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].dtype != 'float64':\n",
    "        X[col]=X[col].astype(dtype='float64')\n",
    "\n",
    "# All features are now float64\n",
    "display(df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a553cb4540c55849"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we split the dataset into training and testing data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68179e197ecd40c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f616f241f4ce5fa4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the data is normalized."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b62f2c9c32d2dd8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "# First 10 rows of scaled features\n",
    "display(X_scaled.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640d60e",
   "metadata": {},
   "source": [
    "## Modeling: Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92217bc3",
   "metadata": {},
   "source": [
    "Here we build regression model and train it with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031df99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c1f56",
   "metadata": {},
   "source": [
    "Here we get start value of y (intercept) when x is zero and coefficient of function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept (scalar)\n",
    "b0 = model.intercept_.item()\n",
    "\n",
    "# Coefficients (1D array)\n",
    "coefs = model.coef_.ravel()\n",
    "\n",
    "print(f\"Intercept: {b0:.2f}\")\n",
    "for col, coef in zip(X.columns, coefs):\n",
    "    print(f\"{col}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f0123",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_cols = X_scaled.columns\n",
    "number_of_plots = len(feature_cols)\n",
    "\n",
    "rows, cols = (number_of_plots + 2) // 3, 3  \n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    xs = np.linspace(X_scaled.min(), X_scaled.max())\n",
    "\n",
    "    ys = b0 + coefs[i] * xs\n",
    "    axes[i].plot(xs, ys)\n",
    "    axes[i].scatter(X_scaled[col], y_train)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Y House Price of Unit Area')   \n",
    "    axes[i].set_title(f\"Plot {i+1}\")\n",
    "    \n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression metrics\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "743627b19c2a7b54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"Mean absolute error: %.2f\" % mean_absolute_error(y_test, preds))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1e98584ad8a43e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling: Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a44636d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we convert the target value into binary. We calculate the average house price, and see if the price is over or under the average. 1 is over, and 0 is under."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4427612d12bfedd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate average\n",
    "y_avg = np.average(y_test)\n",
    "display(f\"Average price: {y_avg:.4f}\")\n",
    "\n",
    "# Transform y into binary: 0 if under average, 1 if equal or above\n",
    "y_binary = (y_train >= y_avg).astype(int)\n",
    "y_binary_test = (y_test >= y_avg).astype(int)\n",
    "display(y_binary[:10])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8935672b9d092296"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building and validating a logistic regression model\n",
    "\n",
    "Here we build the logistic regression model using the training data and the binary target values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6c985b1092c9210"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#build and fit model\n",
    "reg = LogisticRegression(solver=\"lbfgs\")\n",
    "reg.fit(X_scaled, y_binary.values.ravel())\n",
    "\n",
    "display(\"Coefficients: \",reg.coef_)\n",
    "display(\"Intercept: \", reg.intercept_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3cdd2227aa6448a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a9f2000da0f89e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = cross_val_predict(estimator=reg, X=X_test, y=y_binary_test.values.ravel(), cv=10)\n",
    "\n",
    "cm = confusion_matrix(y_binary_test.values.ravel(), y_pred)\n",
    "accuracy = accuracy_score(y_binary_test.values.ravel(), y_pred)\n",
    "\n",
    "print(\"Accuracy: %0.2f\" % accuracy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# visualize confusion matrix\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# include counts\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf6aeb2b872f716a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting probability estimates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a28fc43ed9fc829"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4ce05a31ef5bcb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
